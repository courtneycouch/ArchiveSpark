{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting embedded resources from webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.archive.archivespark._\n",
    "import org.archive.archivespark.implicits._\n",
    "import org.archive.archivespark.enrich.functions._\n",
    "import org.archive.archivespark.specific.warc._\n",
    "import org.archive.archivespark.specific.warc.enrichfunctions._\n",
    "import org.archive.archivespark.specific.warc.implicits._\n",
    "import org.archive.archivespark.specific.warc.specs._\n",
    "import org.apache.hadoop.io.compress.GzipCodec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "In the example, the Web archive dataset will be loaded from local WARC / CDX files, using `WarcCdxHdfsSpec`, but any other [Data Specification (DataSpec)](https://github.com/helgeho/ArchiveSpark/blob/master/docs/DataSpecs.md) can be used here as well in order to load your records from different local or remote sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val path = \"/data/archiveit/ArchiveIt-Collection-2950\"\n",
    "val cdxPath = path + \"/cdx/*.cdx.gz\"\n",
    "val warcPath = path + \"/warc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val records = ArchiveSpark.load(WarcCdxHdfsSpec(cdxPath, warcPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering irrelevant records\n",
    "\n",
    "Embeds are specific to webpages, so we can filter out videos, images, stylesheets and any other files except for webpages ([mime type](https://en.wikipedia.org/wiki/Media_type) *text/html*), as well as webpages that were unavailable when they were crawled either ([status code](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) == 200). In addition to that, we also filter URLs here to only keep pages under *occupylowell.org*, to reduce the size of the dataset for this example.\n",
    "\n",
    "*It is important to note that this filtering is done only based on metadata, so up to this point ArchiveSpark does not even touch the actual Web archive records, which is the core efficiency feature of ArchiveSpark.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val pages = records.filter(r => r.mime == \"text/html\" && r.status == 200 && r.surtUrl.startsWith(\"org,occupylowell)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the first record in our remaining dataset, we can see that this indeed is of type *text/html* and was *online* (status 200) at the time of crawl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"record\" : {\n",
       "    \"surtUrl\" : \"org,occupylowell)/\",\n",
       "    \"timestamp\" : \"20120107063734\",\n",
       "    \"originalUrl\" : \"http://occupylowell.org/\",\n",
       "    \"mime\" : \"text/html\",\n",
       "    \"status\" : 200,\n",
       "    \"digest\" : \"NG6JBJ5VEZRU6FRYULHYBRHVNDFCPFR7\",\n",
       "    \"redirectUrl\" : \"-\",\n",
       "    \"meta\" : \"-\",\n",
       "    \"compressedSize\" : 8020\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages.peekJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates\n",
    "\n",
    "In order to save processing time, we remove duplicate websites (based on the digest in the CDX records) and only keep the earliest snapshot for each content. This will be cached, so that we do not need to compute it every time we want to access that collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val earliest = pages.distinctValue(_.digest) {(a, b) => if (a.time < b.time) a else b}.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Extract embedded resources\n",
    "\n",
    "In this example we want to extract stylesheets, hence we are interested in `link` tags with attribute `rel=\"stylesheet\"`. Similarly, we could also extract images or other resources.\n",
    "\n",
    "We first need to define the required [Enrich Function](https://github.com/helgeho/ArchiveSpark/blob/master/docs/EnrichFuncs.md) to enrich our metadata with the URLs (in SURT format) of the embedded stylesheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val Stylesheets = Html.all(\"link\").mapMulti(\"stylesheets\") { linkTags: Seq[String] => linkTags.filter(_.contains(\"rel=\\\"stylesheet\\\"\"))}\n",
    "val StylesheetUrls = SURT.of(HtmlAttribute(\"href\").ofEach(Stylesheets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"record\" : {\n",
       "    \"surtUrl\" : \"org,occupylowell)/forums/showthread.php?action=nextnewest&tid=15\",\n",
       "    \"timestamp\" : \"20120501044456\",\n",
       "    \"originalUrl\" : \"http://occupylowell.org/forums/showthread.php?tid=15&action=nextnewest\",\n",
       "    \"mime\" : \"text/html\",\n",
       "    \"status\" : 200,\n",
       "    \"digest\" : \"TBED6JFUUP4MM3I2PTUZW3ZOZGM4RQ4L\",\n",
       "    \"redirectUrl\" : \"-\",\n",
       "    \"meta\" : \"-\",\n",
       "    \"compressedSize\" : 3009\n",
       "  },\n",
       "  \"payload\" : {\n",
       "    \"string\" : {\n",
       "      \"html\" : {\n",
       "        \"link\" : {\n",
       "          \"stylesheets\" : [ {\n",
       "            \"attributes\" : {\n",
       "              \"href\" : {\n",
       "                \"SURT\" : \"org,occupylowell)/forums/cache/themes/theme3/css3.css\"\n",
       "              }\n",
       "            }\n",
       "          }, {\n",
       "            \"attributes\" : {\n",
       "              \"href\" : {\n",
       "                \"SURT\" : \"org,occupylowell)/f..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest.enrich(StylesheetUrls).peekJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the relevant embeds / stylesheets in the dataset\n",
    "\n",
    "At this point, we have to access the original dataset `records` again, as the stylesheets are not among the filtered `pages`.\n",
    "A `join` operation is used to filter the records in the dataset and keep only the previously extracted stylesheet files. As a `join` is performed on the keys in the dataset, we introduce a dummy value (`true`) here to make the URL the key of the records. For more information please read the [Spark Programming Guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val stylesheetUrls = earliest.flatMapValues(StylesheetUrls).collect.toSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val stylesheetUrls = earliest.flatMapValues(StylesheetUrls).distinct.map(url => (url, true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val stylesheets = records.map(r => (r.surtUrl, r)).join(stylesheetUrls).map{case (url, (record, dummy)) => record}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, we again remove duplicates in the stylesheet dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val distinctStylesheets = stylesheets.distinctValue(_.digest) {(a, b) => if (a.time < b.time) a else b}.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"record\" : {\n",
       "    \"surtUrl\" : \"org,occupylowell)/wp-content/themes/coraline/style.css\",\n",
       "    \"timestamp\" : \"20120424033905\",\n",
       "    \"originalUrl\" : \"http://occupylowell.org/wp-content/themes/coraline/style.css\",\n",
       "    \"mime\" : \"text/css\",\n",
       "    \"status\" : 200,\n",
       "    \"digest\" : \"D6BMRWYNLTNVOMT32BHJ362K3YXNO5VO\",\n",
       "    \"redirectUrl\" : \"-\",\n",
       "    \"meta\" : \"-\",\n",
       "    \"compressedSize\" : 5765\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinctStylesheets.peekJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save the relevant embeds\n",
    "\n",
    "There are different options to save the embeds datasets. One way would be to save the embeds as WARC records as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distinctStylesheets.saveAsWarc(\"stylesheets.warc.gz\", WarcMeta(publisher = \"Internet Archive\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to enrich the metadata of the stylesheets with their actual content and save it as JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val enriched = distinctStylesheets.enrich(StringContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"record\" : {\n",
       "    \"surtUrl\" : \"org,occupylowell)/wp-content/themes/coraline/style.css\",\n",
       "    \"timestamp\" : \"20120424033905\",\n",
       "    \"originalUrl\" : \"http://occupylowell.org/wp-content/themes/coraline/style.css\",\n",
       "    \"mime\" : \"text/css\",\n",
       "    \"status\" : 200,\n",
       "    \"digest\" : \"D6BMRWYNLTNVOMT32BHJ362K3YXNO5VO\",\n",
       "    \"redirectUrl\" : \"-\",\n",
       "    \"meta\" : \"-\",\n",
       "    \"compressedSize\" : 5765\n",
       "  },\n",
       "  \"payload\" : {\n",
       "    \"string\" : \"/*\\nTheme Name: Coraline\\nTheme URI: http://wordpress.org/extend/themes/coraline/\\nDescription: A squeaky-clean theme featuring a custom menu, header, background, and layout. Coraline supports 7 widget areas (up to 3 in the sidebar, four in the footer) and featured images (thumbnails for gallery posts and custom header images for posts and pages). It includes style..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched.peekJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*By adding a .gz extension to the output path, the data will be automatically compressed with GZip.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enriched.saveAsJson(\"stylesheets.json.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn how to convert and save the dataset to some custom format, please see the recipe on [Extracting title + text from a selected set of URLs](Selected_Title-and-Text.ipynb).\n",
    "\n",
    "For more recipes, please check the [ArchiveSpark documentation](https://github.com/helgeho/ArchiveSpark/blob/master/docs/README.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArchiveSpark latest (Spark 2.2.0) dynamic alloc",
   "language": "",
   "name": "archivespark_dynamic"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
